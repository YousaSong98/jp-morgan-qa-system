{"cells":[{"cell_type":"code","execution_count":null,"id":"529dc42f","metadata":{"id":"529dc42f","outputId":"5582f47d-e5f4-403b-d119-7ae02b25f065","colab":{"referenced_widgets":["87669f7da9194434aea237b22578a6b5"]}},"outputs":[{"name":"stderr","output_type":"stream","text":["Reusing dataset squad (C:\\Users\\ktygz\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87669f7da9194434aea237b22578a6b5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","data = load_dataset('squad')"]},{"cell_type":"code","execution_count":null,"id":"82ebfc1d","metadata":{"id":"82ebfc1d"},"outputs":[],"source":["from tqdm.auto import tqdm  # for showing progress bar\n","def add_end_idx(answers, contexts):\n","    new_answers = []\n","    for answer, context in tqdm(zip(answers, contexts)):\n","        # quick reformating to remove lists\n","        answer['text'] = answer['text'][0]\n","        answer['answer_start'] = answer['answer_start'][0]\n","        # gold_text refers to the answer we are expecting to find in context\n","        gold_text = answer['text']\n","        # we already know the start index\n","        start_idx = answer['answer_start']\n","        # and ideally this would be the end index...\n","        end_idx = start_idx + len(gold_text)\n","\n","        # ...however, sometimes squad answers are off by a character or two\n","        if context[start_idx:end_idx] == gold_text:\n","            # if the answer is not off :)\n","            answer['answer_end'] = end_idx\n","        else:\n","            # this means the answer is off by 1-2 tokens\n","            for n in [1, 2]:\n","                if context[start_idx-n:end_idx-n] == gold_text:\n","                    answer['answer_start'] = start_idx - n\n","                    answer['answer_end'] = end_idx - n\n","        new_answers.append(answer)\n","    return new_answers\n","\n","def prep_data(dataset):\n","    questions = dataset['question']\n","    contexts = dataset['context']\n","    answers = add_end_idx(\n","        dataset['answers'],\n","        contexts\n","    )\n","    return {\n","        'question': questions,\n","        'context': contexts,\n","        'answers': answers\n","    }"]},{"cell_type":"code","execution_count":null,"id":"621fcfa0","metadata":{"id":"621fcfa0","outputId":"1820e063-1766-428d-81c9-03a199c14ad3","colab":{"referenced_widgets":["296070a4c688409da2138a8134b9f802"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"296070a4c688409da2138a8134b9f802","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = prep_data(data['train'])"]},{"cell_type":"code","execution_count":null,"id":"a22bad53","metadata":{"id":"a22bad53"},"outputs":[],"source":["subset_size = 100\n","dataset['question'] = dataset['question'][:subset_size]\n","dataset['context'] = dataset['context'][:subset_size]\n","dataset['answers'] = dataset['answers'][:subset_size]"]},{"cell_type":"code","execution_count":null,"id":"eb83297a","metadata":{"id":"eb83297a"},"outputs":[],"source":["from transformers import BertTokenizerFast\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","# tokenize\n","train = tokenizer(dataset['context'], dataset['question'],\n","                  truncation=True, padding='max_length',\n","                  max_length=512, return_tensors='pt')"]},{"cell_type":"code","execution_count":null,"id":"329cea17","metadata":{"id":"329cea17","outputId":"08afb973-315a-4286-cc42-34fa1178428e","colab":{"referenced_widgets":["ac79174bab0d419c9543153000018f94"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac79174bab0d419c9543153000018f94","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def add_token_positions(encodings, answers):\n","    # initialize lists to contain the token indices of answer start/end\n","    start_positions = []\n","    end_positions = []\n","    for i in tqdm(range(len(answers))):\n","        # append start/end token position using char_to_token method\n","        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n","        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n","\n","        # if start position is None, the answer passage has been truncated\n","        if start_positions[-1] is None:\n","            start_positions[-1] = tokenizer.model_max_length\n","        # end position cannot be found, char_to_token found space, so shift position until found\n","        shift = 1\n","        while end_positions[-1] is None:\n","            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n","            shift += 1\n","    # update our encodings object with the new token-based start/end positions\n","    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n","\n","add_token_positions(train, dataset['answers'])"]},{"cell_type":"code","execution_count":null,"id":"5d4b24e3","metadata":{"id":"5d4b24e3"},"outputs":[],"source":["import torch\n","class SquadDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)\n","\n","# build datasets for both our training data\n","train_dataset = SquadDataset(train)"]},{"cell_type":"code","execution_count":null,"id":"86609f4f","metadata":{"id":"86609f4f"},"outputs":[],"source":["loader = torch.utils.data.DataLoader(train_dataset,\n","                                     batch_size=16,\n","                                     shuffle=True)"]},{"cell_type":"code","execution_count":null,"id":"d3c996c2","metadata":{"id":"d3c996c2","outputId":"4fc1d200-d24f-4ac0-cfd1-70592122f769"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","C:\\Users\\ktygz\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["from transformers import AdamW\n","from transformers import BertForMaskedLM\n","\n","model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","model.train()\n","\n","optim = AdamW(model.parameters(), lr=5e-5)"]},{"cell_type":"code","execution_count":null,"id":"9d23a065","metadata":{"id":"9d23a065","outputId":"1ada2e9a-cc09-4cd0-8a7c-4fd941725bc6","colab":{"referenced_widgets":["1ca2a488b5a94f28aede09a1583d035b","2eade2f4b2204a539f9648cb7cd60e9d","0313bdb716db4058b23f6f25eec86a0e"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ca2a488b5a94f28aede09a1583d035b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/7 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["C:\\Users\\ktygz\\AppData\\Local\\Temp/ipykernel_1380/1996366417.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2eade2f4b2204a539f9648cb7cd60e9d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/7 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0313bdb716db4058b23f6f25eec86a0e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/7 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["for epoch in range(2):\n","    loop = tqdm(loader)\n","    \n","    for batch in loop:\n","        \n","        optim.zero_grad()\n","        \n","        input_ids = batch[\"input_ids\"]\n","        \n","        batch['labels'] = input_ids.detach().clone()\n","        \n","        attention_mask = batch[\"attention_mask\"]\n","        \n","        rand = torch.rand(input_ids.shape)\n","        mask_arr = (rand < 0.15) * (input_ids != 101) * (input_ids != 102)\n","        selection = torch.flatten((mask_arr[0]).nonzero()).tolist()\n","        batch[\"input_ids\"][0, selection] = 103\n","        \n","        outputs = model(input_ids = batch[\"input_ids\"], attention_mask= attention_mask, labels = batch[\"labels\"])\n","        \n","        loss = outputs[0]\n","        loss.sum().backward()\n","        optim.step()\n","\n","        loop.set_description(f'Epoch {epoch}')\n","        loop.set_postfix(loss=loss.item())"]},{"cell_type":"code","execution_count":null,"id":"30350310","metadata":{"id":"30350310"},"outputs":[],"source":["model.save_pretrained('./fine_tuned_v1')"]},{"cell_type":"code","execution_count":null,"id":"6c21f5f6","metadata":{"id":"6c21f5f6"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"fine_tuning.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}